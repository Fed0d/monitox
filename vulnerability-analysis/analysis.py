import warnings

import pytorch_lightning as pl
import torch
import torch.nn as nn
from transformers import BertModel
from transformers import BertTokenizerFast as BertTokenizer

warnings.filterwarnings("ignore")

RANDOM_SEED = 42
pl.seed_everything(RANDOM_SEED)
BERT_MODEL_NAME = "distilbert/distilbert-base-uncased-finetuned-sst-2-english"
tokenizer = BertTokenizer.from_pretrained(BERT_MODEL_NAME)
LABEL_COLUMNS = ["benign", "jailbreak", "prompt_injection"]
warmup_steps = 185
total_training_steps = 926
MAX_TOKEN_COUNT = None


class InputClassifier(pl.LightningModule):
    def __init__(self, n_classes: int, n_training_steps=None, n_warmup_steps=None):
        super().__init__()
        self.bert = BertModel.from_pretrained(BERT_MODEL_NAME, return_dict=True)
        self.classifier = nn.Linear(self.bert.config.hidden_size, n_classes)
        self.n_training_steps = n_training_steps
        self.n_warmup_steps = n_warmup_steps
        self.criterion = nn.BCELoss()

    def forward(self, input_ids, attention_mask, labels=None):
        output = self.bert(input_ids, attention_mask=attention_mask)
        output = self.classifier(output.pooler_output)
        output = torch.sigmoid(output)
        loss = 0
        if labels is not None:
            loss = self.criterion(output, labels)
        return loss, output


checkpoint = torch.load("model.ckpt")
loaded_model = InputClassifier(
    n_classes=len(LABEL_COLUMNS),
    n_training_steps=total_training_steps,
    n_warmup_steps=warmup_steps,
)

loaded_model.load_state_dict(checkpoint["state_dict"])
loaded_model.eval()
loaded_model.freeze()


def evaluate_user_prompt(prompt: str) -> dict[str, float]:
    encoding = tokenizer.encode_plus(
        prompt,
        add_special_tokens=True,
        max_length=None,
        return_token_type_ids=False,
        padding="max_length",
        truncation=True,
        return_attention_mask=True,
        return_tensors="pt",
    )
    _, test_prediction = loaded_model(encoding["input_ids"], encoding["attention_mask"])
    predictions = test_prediction.flatten().numpy()
    return {
        str(label): float(probability)
        for (label, probability) in (zip(LABEL_COLUMNS, predictions))
    }
